# -*- coding: utf-8 -*-
"""ML FellowShip Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oseCPvA1aZD71zRSBQIs24cNO327P3B_

# Task
# TASK: Prepare TMDB 5000 dataset for a movie recommendation system

# 1. Load the datasets
# 2. Merge 'tmdb_5000_movies.csv' and 'tmdb_5000_credits.csv' on 'title'
# 3. Extract and clean relevant columns: 'genres', 'keywords', 'cast', 'crew', 'overview'
# 4. Create a new 'tags' column by combining useful text from the above
# 5. Clean the text: lowercase, remove spaces, punctuation, stopwords (optional)
# 6. Return the final DataFrame with columns: 'movie_id', 'title', 'tags'

import pandas as pd
import ast

# Load datasets
movies = pd.read_csv("tmdb_5000_movies.csv")
credits = pd.read_csv("tmdb_5000_credits.csv")

# Merge datasets on title
movies = movies.merge(credits, on='title')

# Keep only required columns
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

# Function to convert stringified list to list of names
def extract_names(obj, key='name', limit=None):
    try:
        items = ast.literal_eval(obj)
        names = [item[key] for item in items]
        if limit:
            names = names[:limit]
        return names
    except:
        return []

# Extract genres, keywords, cast (top 3), director
movies['genres'] = movies['genres'].apply(lambda x: extract_names(x))
movies['keywords'] = movies['keywords'].apply(lambda x: extract_names(x))
movies['cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))
movies['crew'] = movies['crew'].apply(lambda x: [d['name'] for d in ast.literal_eval(x) if d['job'] == 'Director'])

# Combine text fields into a single 'tags' column
movies['overview'] = movies['overview'].fillna('')
movies['tags'] = movies['overview'] + ' ' + \
                 movies['genres'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['keywords'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['cast'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['crew'].apply(lambda x: ' '.join(x))

# Drop unneeded columns
movies = movies[['movie_id', 'title', 'tags']]


Here is all the data you need:
"tmdb_5000_credits.csv"
"tmdb_5000_movies.csv"

## Data loading

### Subtask:
Load the two CSV files into pandas DataFrames.

**Reasoning**:
Load the two CSV files into pandas DataFrames.
"""

import pandas as pd

movies = pd.read_csv("tmdb_5000_movies.csv")
credits = pd.read_csv("tmdb_5000_credits.csv")

"""## Data preparation

### Subtask:
Merge the two dataframes, `movies` and `credits`, based on the 'title' column.

**Reasoning**:
Merge the movies and credits dataframes on the 'title' column.
"""

movies = movies.merge(credits, on='title')

"""## Data wrangling

### Subtask:
Select relevant columns and extract information from specific columns using the provided helper function.

**Reasoning**:
Select the relevant columns and apply the extract_names function to the specified columns, modifying it for the 'crew' column to extract directors' names.
"""

# Keep only required columns
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

# Function to convert stringified list to list of names
def extract_names(obj, key='name', limit=None):
    try:
        items = ast.literal_eval(obj)
        if key == 'name':
            names = [item[key] for item in items]
            if limit:
                names = names[:limit]
            return names
        elif key == 'job' and isinstance(items, list):
            names = [item['name'] for item in items if item.get('job') == 'Director']
            return names
        return []
    except:
        return []

# Extract genres, keywords, cast (top 3), director
movies['genres'] = movies['genres'].apply(lambda x: extract_names(x))
movies['keywords'] = movies['keywords'].apply(lambda x: extract_names(x))
movies['cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))
movies['crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))

"""**Reasoning**:
The previous code block generated SettingWithCopyWarnings.  To fix this, use `.loc` to assign the new values to the DataFrame.  Also, the `extract_names` function for the `crew` column is not correctly extracting director names.  It should check for the `job` key being equal to 'Director' within the `try` block.


"""

import ast

# Keep only required columns
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

# Function to convert stringified list to list of names
def extract_names(obj, key='name', limit=None):
    try:
        items = ast.literal_eval(obj)
        if key == 'name':
            names = [item[key] for item in items]
            if limit:
                names = names[:limit]
            return names
        elif key == 'job' and isinstance(items, list):
            names = [item['name'] for item in items if item.get('job') == 'Director']
            return names
        return []
    except (ValueError, TypeError, IndexError):
        return []

# Extract genres, keywords, cast (top 3), director
movies.loc[:, 'genres'] = movies['genres'].apply(lambda x: extract_names(x))
movies.loc[:, 'keywords'] = movies['keywords'].apply(lambda x: extract_names(x))
movies.loc[:, 'cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))
movies.loc[:, 'crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))

"""**Reasoning**:
The error message indicates that the `ast` module is not imported.  I need to import it before using `ast.literal_eval`.


"""

import ast

# Load the original movie dataset to retrieve the required columns
movies = pd.read_csv("tmdb_5000_movies.csv")
credits = pd.read_csv("tmdb_5000_credits.csv")
movies = movies.merge(credits, on='title')


# Now you can select the required columns
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

# ... (rest of your code) ...
# Function to convert stringified list to list of names
def extract_names(obj, key='name', limit=None):
    try:
        items = ast.literal_eval(obj)
        if key == 'name':
            names = [item[key] for item in items]
            if limit:
                names = names[:limit]
            return names
        elif key == 'job' and isinstance(items, list):
            names = [item['name'] for item in items if item.get('job') == 'Director']
            return names
        return []
    except (ValueError, TypeError, IndexError):
        return []

# Extract genres, keywords, cast (top 3), director
movies.loc[:, 'genres'] = movies['genres'].apply(lambda x: extract_names(x))
movies.loc[:, 'keywords'] = movies['keywords'].apply(lambda x: extract_names(x))
movies.loc[:, 'cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))
movies.loc[:, 'crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))

"""## Feature engineering

### Subtask:
Combine the relevant text columns ('overview', 'genres', 'keywords', 'cast', 'crew') into a new 'tags' column.

**Reasoning**:
Combine the relevant text columns ('overview', 'genres', 'keywords', 'cast', 'crew') into a new 'tags' column, handling missing values in 'overview'.
"""

# Fill missing values in 'overview' with empty strings
movies['overview'] = movies['overview'].fillna('')

# Combine text fields into a single 'tags' column
movies['tags'] = movies['overview'] + ' ' + \
                 movies['genres'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['keywords'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['cast'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['crew'].apply(lambda x: ' '.join(x))

"""## Data preparation

### Subtask:
Drop unnecessary columns from the DataFrame, leaving only 'movie_id', 'title', and 'tags'.

**Reasoning**:
Select only the required columns 'movie_id', 'title', and 'tags' from the movies DataFrame.
"""

movies = movies[['movie_id', 'title', 'tags']]

"""## Summary:

### 1. Q&A

No questions were posed in the provided task description.


### 2. Data Analysis Key Findings

*   The datasets `tmdb_5000_movies.csv` and `tmdb_5000_credits.csv` were successfully merged based on the 'title' column.
*   A new 'tags' column was created by combining 'overview', 'genres', 'keywords', 'cast', and 'crew' information, creating a text-based representation of each movie for content-based filtering.
*   The 'cast' column was limited to the top 3 actors for each movie.
*   Only the director's name was extracted from the 'crew' column.
*   Missing values in the 'overview' column were filled with empty strings.


### 3. Insights or Next Steps

*   The 'tags' column is now ready for text vectorization techniques (TF-IDF, word embeddings) to build a content-based movie recommendation system.
*   Explore other features like budget, revenue, popularity, and vote counts to incorporate into the recommendation model for a more comprehensive approach.

"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import ast

# Load the original movie dataset to retrieve the required columns
movies = pd.read_csv("tmdb_5000_movies.csv")
credits = pd.read_csv("tmdb_5000_credits.csv")
movies = movies.merge(credits, on='title')

# Now you can select the required columns
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

# Function to convert stringified list to list of names
def extract_names(obj, key='name', limit=None):
    try:
        items = ast.literal_eval(obj)
        if key == 'name':
            names = [item[key] for item in items]
            if limit:
                names = names[:limit]
            return names
        elif key == 'job' and isinstance(items, list):
            names = [item['name'] for item in items if item.get('job') == 'Director']
            return names
        return []
    except (ValueError, TypeError, IndexError):
        return []

# Extract genres, keywords, cast (top 3), director
movies.loc[:, 'genres'] = movies['genres'].apply(lambda x: extract_names(x))
movies.loc[:, 'keywords'] = movies['keywords'].apply(lambda x: extract_names(x))
movies.loc[:, 'cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))
movies.loc[:, 'crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))

# Fill missing values in 'overview' with empty strings
movies['overview'] = movies['overview'].fillna('')

# Combine text fields into a single 'tags' column
movies['tags'] = movies['overview'] + ' ' + \
                 movies['genres'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['keywords'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['cast'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['crew'].apply(lambda x: ' '.join(x))

# Now proceed with your vectorization and recommendation code
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(movies['tags'])

# 2. Similarity Calculation
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# 3. Recommendation Function
def get_recommendations(title, cosine_sim=cosine_sim):
    idx = movies[movies['title'] == title].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]  # Get top 10 similar movies
    return movies['title'].iloc[[i[0] for i in sim_scores]]

# 4. Testing
recommendations = get_recommendations('Tangled')

# Print or display the recommendations
print(recommendations)

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import ast
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

# Download NLTK resources if not already downloaded
nltk.download('stopwords')

# Load the original movie dataset to retrieve the required columns
movies = pd.read_csv("tmdb_5000_movies.csv")
credits = pd.read_csv("tmdb_5000_credits.csv")
movies = movies.merge(credits, on='title')

# ... (rest of the code remains the same as before) ...

def get_recommendations(title, cosine_sim=cosine_sim):
    # Check if movie title exists in the dataset
    if title not in movies['title'].values:
        print("Movie title not found. Please enter another title.")
        return None  # Indicate that no recommendations were generated

    # If title exists, proceed with generating recommendations
    idx = movies[movies['title'] == title].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]  # Get top 10 similar movies
    movie_indices = [i[0] for i in sim_scores]
    return movies['title'].iloc[movie_indices]

# --- Testing with loop for invalid titles ---
while True:
    title = input("Enter a movie title: ")
    recommendations = get_recommendations(title)

    if recommendations is not None:  # Recommendations were generated
        print(recommendations)
        break  # Exit the loop

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import ast
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import pickle

def build_movie_recommendation_model():
    """Builds and saves the movie recommendation model."""

    # Download NLTK resources if not already downloaded
    nltk.download('stopwords')

    # Load datasets
    movies = pd.read_csv("tmdb_5000_movies.csv")
    credits = pd.read_csv("tmdb_5000_credits.csv")
    movies = movies.merge(credits, on='title')

    # Keep only required columns
    movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

    # Function to convert stringified list to list of names
    def extract_names(obj, key='name', limit=None):
        try:
            items = ast.literal_eval(obj)
            if key == 'name':
                names = [item[key] for item in items]
                if limit:
                    names = names[:limit]
                return names
            elif key == 'job' and isinstance(items, list):
                names = [item['name'] for item in items if item.get('job') == 'Director']
                return names
            return []
        except (ValueError, TypeError, IndexError):
            return []

    # Extract genres, keywords, cast (top 3), director
    movies.loc[:, 'genres'] = movies['genres'].apply(lambda x: extract_names(x))
    movies.loc[:, 'keywords'] = movies['keywords'].apply(lambda x: extract_names(x))
    movies.loc[:, 'cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))
    movies.loc[:, 'crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))

    # Fill missing values in 'overview' with empty strings
    movies['overview'] = movies['overview'].fillna('')

    # Combine text fields into a single 'tags' column
    movies['tags'] = movies['overview'] + ' ' + \
                     movies['genres'].apply(lambda x: ' '.join(x)) + ' ' + \
                     movies['keywords'].apply(lambda x: ' '.join(x)) + ' ' + \
                     movies['cast'].apply(lambda x: ' '.join(x)) + ' ' + \
                     movies['crew'].apply(lambda x: ' '.join(x))

    # Data Cleaning and Preprocessing
    ps = PorterStemmer()

    def clean_tags(text):
        text = re.sub('[^a-zA-Z0-9 ]', '', text)
        text = text.lower()
        text = ' '.join([ps.stem(word) for word in text.split() if word not in stopwords.words('english')])
        return text

    movies['tags'] = movies['tags'].apply(clean_tags)

    # Text Vectorization and Similarity Calculation
    tfidf = TfidfVectorizer(stop_words='english')
    tfidf_matrix = tfidf.fit_transform(movies['tags'])
    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

    # Save the model
    with open('movie_recommendation_model.pkl', 'wb') as f:
        pickle.dump({'tfidf_vectorizer': tfidf,
                     'cosine_sim_matrix': cosine_sim,
                     'movies_data': movies}, f)

    print("Model saved successfully to 'movie_recommendation_model.pkl'")

def get_recommendations(title, model_path='movie_recommendation_model.pkl'):
    """Loads the model and generates movie recommendations."""

    with open(model_path, 'rb') as f:
        model_data = pickle.load(f)

    tfidf = model_data['tfidf_vectorizer']
    cosine_sim = model_data['cosine_sim_matrix']
    movies = model_data['movies_data']

    if title not in movies['title'].values:
        print("Movie title not found. Please enter another title.")
        return None

    idx = movies[movies['title'] == title].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]  # Get top 10 similar movies
    movie_indices = [i[0] for i in sim_scores]
    return movies['title'].iloc[movie_indices]

# Build the model when the script is run
if __name__ == "__main__":
    build_movie_recommendation_model()

    # --- Testing with loop for invalid titles ---
    while True:
        title = input("Enter a movie title: ")
        recommendations = get_recommendations(title)

        if recommendations is not None:  # Recommendations were generated
            print(recommendations)
            break  # Exit the loop